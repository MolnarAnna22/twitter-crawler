{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, sys, datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"../../python/\")\n",
    "import rg17.text_cleaning as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../../\", \"TrendApproximation\", sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed_tweet_text_file = ph.get(\"stemmed_tweet_file_path\")\n",
    "word_corpus_file = ph.get(\"word_corpus\")\n",
    "model_root_folder = ph.get(\"w2v_root_folder\")\n",
    "w2v_model_dim = ph.get(\"w2v_model_dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(model_root_folder):\n",
    "    os.makedirs(model_root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Load stemmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tweets = pd.read_csv(stemmed_tweet_text_file, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed_tweets = stemmed_tweets[[\"time\",\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert epoch to GMT time (D\u00e1vid uses this format for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"gmt_time\"] = stemmed_tweets[\"time\"].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapshot_hours = [1,4,7,10,13,16,19,22]\n",
    "\n",
    "def round_hour_value(hour_val):\n",
    "    if hour_val % 3 == 2:\n",
    "        return hour_val - 1\n",
    "    elif hour_val % 3 == 0:\n",
    "        return hour_val - 2\n",
    "    else:\n",
    "        return hour_val\n",
    "\n",
    "def get_snapshot_id(gmt_time):\n",
    "    date_rec, time_rec = gmt_time.split()\n",
    "    hour_value = int(time_rec.split(\":\")[0])\n",
    "    rounded_hour = round_hour_value(hour_value)\n",
    "    if rounded_hour == -2:\n",
    "        rounded_hour = 22\n",
    "        dt = datetime.datetime.strptime(date_rec, \"%Y-%m-%d\")\n",
    "        dt_new = dt - datetime.timedelta(days=1)\n",
    "        date_rec = \"%.4i-%.2i-%.2i\" % (dt_new.year, dt_new.month, dt_new.day)\n",
    "    return \"%sT%.2i:00\" % (date_rec, rounded_hour)\n",
    "    \n",
    "print(get_snapshot_id(\"2017-06-11 21:00:59\"))\n",
    "print(get_snapshot_id(\"2017-06-11 00:00:59\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"snapshot_id\"] = stemmed_tweets[\"gmt_time\"].apply(get_snapshot_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"date\"] = stemmed_tweets[\"snapshot_id\"].apply(lambda x: x.split(\"T\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for evaluation timeframes (June 6 - June 11) - for faster preprocessing before W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(stemmed_tweets))\n",
    "stemmed_tweets = stemmed_tweets[(stemmed_tweets[\"date\"] >= \"2017-05-28\") & (stemmed_tweets[\"date\"] <= \"2017-06-11\")]\n",
    "print(len(stemmed_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load selected word corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_words = []\n",
    "with open(word_corpus_file) as f:\n",
    "    for line in f:\n",
    "        selected_words.append(line.rstrip())\n",
    "selected_words = set(selected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(selected_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Filter tweet texts for relevant words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Cleaning based on regexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"cleaned_text\"] = stemmed_tweets[\"text\"].apply(tc.clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) Cleaning based on word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"word_list\"] = stemmed_tweets[\"cleaned_text\"].apply(lambda x: tc.get_words_above_size_limit(x,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c.) Leaving only the selected words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_tweets[\"selected_word_list\"] = stemmed_tweets[\"word_list\"].apply(lambda x: list(set(x).intersection(selected_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_w2v_model(snapshot_id, dump_model=False):\n",
    "    partial_df = stemmed_tweets[stemmed_tweets[\"snapshot_id\"] == snapshot_id]\n",
    "    # dropping tweets with only one word - no use for w2v\n",
    "    partial_df = partial_df[partial_df[\"selected_word_list\"].apply(lambda x: True if len(x) > 2 else False)]\n",
    "    print(\"Number of tweets for training: %i\" % len(partial_df))\n",
    "    w2v_data = list(partial_df[\"selected_word_list\"])\n",
    "    model = gensim.models.Word2Vec(w2v_data, min_count=5, size=w2v_model_dim, batch_words=100)\n",
    "    if dump_model:\n",
    "        output_dir = \"%s/dim_%i/\" % (model_root_folder, w2v_model_dim)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        model.save(fname_or_handle=\"%s/%s.w2v\" % (output_dir, snapshot_id))\n",
    "    return (snapshot_id, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training + Exporting models for all snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapshot_ids = list(stemmed_tweets[\"snapshot_id\"].unique())\n",
    "for snapshot_id in sorted(snapshot_ids):\n",
    "    snapshot_id, _ = train_w2v_model(snapshot_id, dump_model=True)\n",
    "    print(snapshot_id)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}