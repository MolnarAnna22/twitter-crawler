{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(font=\"DejaVu Sans\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../../python/\")\n",
    "from rg17 import evaluate_toplist as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../../\", \"TrendApproximation\", sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_dir = ph.get(\"experiment_dir\")\n",
    "shedule_file_path = ph.get(\"schedule_file_path\")\n",
    "screen_names_file_path = ph.get(\"player_screen_names_file_path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load player accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_accounts = et.load_player_accounts(screen_names_file_path, remove_digits=False, remove_under_score=False, to_lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_accounts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load occurances file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "occurences_pd = pd.read_csv(\"%s/occ_table.csv\" % experiment_dir, sep=\"|\")\n",
    "len(occurences_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "occurences_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping irrelevant snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "occurences_pd[\"date\"] = occurences_pd[\"start_time\"].apply(lambda x: x.split(\"T\")[0])\n",
    "occurences_pd = occurences_pd[~occurences_pd[\"date\"].isin(['2017-06-12','2017-06-13','2017-06-14','2017-06-15','2017-06-16'])]\n",
    "len(occurences_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: lot of missing players? duplications?\n",
    "\n",
    "#### Simona Halep\n",
    "   * @Simona_Halep kor\u00e1bban nem volt el\u0151fordul\u00e1sa - most m\u00e1r van\n",
    "   * de @simonahalep-nak tov\u00e1bbra is vannak..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(player_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(occurences_pd[\"key_word\"].unique()).intersection(set(player_accounts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(player_accounts).difference(set(occurences_pd[\"key_word\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_cols = [str(i) for i in range(1,201,2)]\n",
    "count_cols = [str(i) for i in range(2,201,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional words to examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "special_words = []\n",
    "special_words += [\"rolandgarros\", \"frenchopen\"]\n",
    "special_words += [\"match\", \"play\", \"game\", \"fight\", \"face\", \"result\", \"court\", \"now\", \"today\", \"tomorrow\", \"injury\", \"shock\"]\n",
    "special_words += [\"qualifi\", \"surviv\", \"elimin\", \"domin\"]\n",
    "special_words += [\"birthday\"]\n",
    "special_words += [\"wins\", \"win\", \"won\", \"champion\", \"champ\", \"king\", \"beat\", \"trophy\", \"triumph\", \"overcom\"]\n",
    "special_words += [\"lose\", \"loss\", \"lost\", \"defeat\", \"beaten\", \"broken\", \"break\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Men, Women Finalists in Single tournaments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "special_words += [\"rafa\", \"nadal\", \"rafael\", \"@RafaelNadal\".lower()]\n",
    "special_words += [\"stan\", \"wawrinka\", \"@stanwawrinka\".lower()]\n",
    "special_words += [\"andy\", \"murray\", \"@andy_murray\".lower()]\n",
    "special_words += [\"thiem\", \"dominic\", \"@ThiemDomi\".lower()]\n",
    "special_words += [\"novak\", \"djokovic\", \"@DjokerNole\".lower()]\n",
    "special_words += ['svitolina', 'elina', \"@ElinaSvitolina\".lower()]\n",
    "special_words += ['carreno', 'busta', 'pablo', \"@pablocarreno91\".lower()]\n",
    "special_words += ['timea', 'bacsinszky', \"@TimeaOfficial\".lower()]\n",
    "special_words += ['jelena', 'ostapenko', \"OstapenkoFC\".lower()]\n",
    "special_words += ['halep', 'simona', \"@Simona_Halep\".lower()]\n",
    "special_words += ['karolina', 'pliskova', \"@KaPliskova\".lower()]\n",
    "special_words += ['mladenovic', 'kristina', \"@KikiMladenovic\".lower()]\n",
    "special_words += ['caroline', 'wozniacki', \"@CaroWozniacki\".lower()]\n",
    "special_words += ['caroline', 'garcia', \"@CaroGarcia\".lower()]\n",
    "special_words += ['nishikori', 'kei', \"@keinishikori\".lower()]\n",
    "special_words += ['cilic', 'marin', \"@cilic_marin\".lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "occurences_pd = occurences_pd[occurences_pd[\"key_word\"].isin(player_accounts+special_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(occurences_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "occurences_pd.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restructure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pd.DataFrame()\n",
    "size = len(word_cols)\n",
    "for idx, row in occurences_pd.iterrows():\n",
    "    start_time, key_word, key_word_count = row[\"start_time\"], row[\"key_word\"], row[\"count\"]\n",
    "    hour = start_time.split(\"T\")[1][:2]\n",
    "    hours, times, key_words, key_word_counts = zip(*((hour, start_time, key_word, key_word_count) for i in range(size)))\n",
    "    values = [times, hours, key_words, key_word_counts, row[word_cols], row[count_cols]]\n",
    "    cols = [\"time\",\"hour\",\"word_1\", \"word_1_count\", \"word_2\", \"word_2_count\"]\n",
    "    some_occs = list(zip(*values))\n",
    "    tmp_df = pd.DataFrame(some_occs, columns=cols)\n",
    "    # exclude no hits\n",
    "    tmp_df = tmp_df[tmp_df[\"word_2_count\"] > 0]\n",
    "    # exclude self occurences\n",
    "    tmp_df = tmp_df[tmp_df[\"word_2\"] != key_word]\n",
    "    pair_occs_df = pd.concat([pair_occs_df, tmp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pair_occs_df.reset_index()\n",
    "del pair_occs_df[\"index\"]\n",
    "print(len(pair_occs_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df.to_csv(\"%s/full_pair_occs.csv\" % experiment_dir, sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "raise RuntimeError(\"Reading from file!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pair_occs_df = pd.read_csv(\"%s/full_pair_occs.csv\" % experiment_dir, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Dropping excluded words: @rolandgarros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df = pair_occs_df[~pair_occs_df[\"word_2\"].isin([\"@rolandgarros\"])]\n",
    "print(len(pair_occs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate co-occurence statistics for snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"date\"] = pair_occs_df[\"time\"].apply(lambda x: x.split(\"T\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_for_stats_df = pair_occs_df#[~pair_occs_df[\"date\"].isin(['2017-06-11'])]\n",
    "print(len(pair_occs_for_stats_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Actually I should compute the occ_scores temporally (only taking into account the past occurences...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Calculate global mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_for_stats_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_count_occs = pair_occs_for_stats_df.groupby(by=[\"word_1\",\"word_2\"])[\"time\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the mean of the fractions for all snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_cols = [\"word_1_count\",\"word_2_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_mean_occs = pair_occs_for_stats_df.groupby(by=[\"word_1\",\"word_2\"])[count_cols].sum().reset_index()\n",
    "global_mean_occs[\"global\"] = global_mean_occs[\"word_2_count\"] / global_mean_occs[\"word_1_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: If (word_1,word_2) occurring in only 2-3 snapshot is not excluded then global distribution has spikes at 1.0, 0.5, 1/3 etc. - we get a clean distribution only if I remove infrequent word_2-s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "global_mean_occs[\"global\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_mean_occs[\"global\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_mean_occs[\"key\"] = list(zip(global_mean_occs[\"word_1\"],global_mean_occs[\"word_2\"]))\n",
    "GLOBAL_MEANS = dict(zip(global_mean_occs[\"key\"],global_mean_occs[\"global\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(global_mean_occs), len(GLOBAL_MEANS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "GLOBAL_MEANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) Calculate snapshot mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapshot_mean_occs = pair_occs_for_stats_df.groupby(by=[\"word_1\",\"word_2\",\"hour\"])[count_cols].sum().reset_index()\n",
    "snapshot_mean_occs[\"snapshot\"] = snapshot_mean_occs[\"word_2_count\"] / snapshot_mean_occs[\"word_1_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The distribution is not clean due to the fact that I do not filter for pairs occurring in at least 2-3 same time of day snapshot!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapshot_mean_occs[\"snapshot\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapshot_mean_occs[\"key\"] = list(zip(snapshot_mean_occs[\"word_1\"],snapshot_mean_occs[\"word_2\"],snapshot_mean_occs[\"hour\"]))\n",
    "SNAPSHOT_MEANS = dict(zip(snapshot_mean_occs[\"key\"],snapshot_mean_occs[\"snapshot\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNAPSHOT_MEANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate occurence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_with_global_score(row):\n",
    "    key = (row[\"word_1\"],row[\"word_2\"])\n",
    "    return GLOBAL_MEANS[key] if key in GLOBAL_MEANS else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"global_val\"] = pair_occs_df.apply(fill_with_global_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_with_snapshot_score(row):\n",
    "    key = (row[\"word_1\"],row[\"word_2\"],row[\"hour\"])\n",
    "    return SNAPSHOT_MEANS[key] if key in SNAPSHOT_MEANS else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df[\"snapshot_val\"] = pair_occs_df.apply(fill_with_snapshot_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_occs_df.to_csv(\"%s/occ_pairs_with_scores.csv\" % experiment_dir, index=False, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_occs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def calculate_norm_score(row, c_val, alpha=0, eps=0.0):\n",
    "    val_key = \"rel_count_%i\" % c_val\n",
    "    global_norm = row[\"global_val\"][val_key] if row[\"global_val\"] != 0 else 0\n",
    "    snapshot_norm = row[\"snapshot_val\"][val_key] if row[\"snapshot_val\"] != 0 else 0\n",
    "    # both normalization constant is missing\n",
    "    if global_norm == 0 and snapshot_norm == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return (eps + (2.0 + alpha) * row[val_key]) / (eps + global_norm + snapshot_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c_val, alpha_val = 1, 0\n",
    "pair_occs_df[\"norm_c%i_a%i\" % (c_val, alpha_val)] = pair_occs_df.apply(lambda x: calculate_norm_score(x,c_val=1, alpha=alpha_val), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pair_occs_df[\"day\"] = pair_occs_df[\"time\"].apply(lambda x: x.split(\"T\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pair_occs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def show_score(w1, w2, score_name=\"norm_c1_a0\"):\n",
    "    filtered_df = pair_occs_df[(pair_occs_df[\"word_1\"] == w1) & (pair_occs_df[\"word_2\"] == w2)]\n",
    "    pivot_scores = pd.pivot_table(filtered_df, values=score_name, index=\"hour\", columns=\"day\")\n",
    "    fig, ax = plt.subplots(figsize=(30,5))\n",
    "    plt.title(\"%s->%s: %i record\" % (w1, w2, len(filtered_df)))\n",
    "    sns.heatmap(pivot_scores, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "schedule_df = pd.read_csv(shedule_file_path, sep=\"|\")\n",
    "schedule_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rafa nadal matches\n",
    "\n",
    "   * the first few matches of Nadal has high scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "name = \"Rafael Nadal\"\n",
    "schedule_df[(schedule_df[\"playerName active\"] == name) | (schedule_df[\"playerName opponent\"] == name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_score(\"@RafaelNadal\",\"match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_score(\"@RafaelNadal\",\"win\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How often are the two finalist mentioned together (Men's single final on 06-11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_score(\"@RafaelNadal\",\"@stanwawrinka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The winner is Nadal (Men's single final on 06-11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_score(\"@RafaelNadal\",\"champion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_score(\"@stanwawrinka\",\"champion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The loser is Wawrinka (Men's single final on 06-11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_score(\"@stanwawrinka\",\"beat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_score(\"@RafaelNadal\",\"beat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadal birthday: June 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_score(\"@RafaelNadal\",\"birthday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novak Djokovic lost on 06-07 - occurences score diminishes after this day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "name = \"Novak Djokovic\"\n",
    "schedule_df[(schedule_df[\"playerName active\"] == name) | (schedule_df[\"playerName opponent\"] == name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_score(\"@DjokerNole\",\"match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Toplists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pair_occs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def get_toplist(w1, snapshot_id, score_name=\"norm_c1_a0\"):\n",
    "    filtered_df = pair_occs_df[(pair_occs_df[\"word_1\"] == w1) & (pair_occs_df[\"time\"] == snapshot_id)]\n",
    "    return filtered_df.sort_values(score_name, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"@stanwawrinka\" and \"final\" is in top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_toplist(\"@RafaelNadal\",\"2017-06-11T07:00\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_toplist(\"@rafaelnadal\",\"2017-06-10T18:00\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"@stanwawrinka\" is in top1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_toplist(\"@RafaelNadal\",\"2017-06-11T10:00\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"win\", \"title\" and \"champion\" is in top words + \"congrat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_toplist(\"@RafaelNadal\",\"2017-06-11T13:00\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_toplist(\"@RafaelNadal\",\"2017-06-11T16:00\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nadal birthday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_toplist(\"@RafaelNadal\",\"2017-06-03T16:00\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_toplist(\"play\",\"2017-06-04T16:00\").head(20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}