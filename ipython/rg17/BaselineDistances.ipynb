{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from datawand.parametrization import ParamHelper\n",
    "ph = ParamHelper(\"../../\", \"TrendApproximation\", sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Store co-occuring words in dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_dir = ph.get(\"experiment_dir\")\n",
    "time_hour_vals = ph.get(\"time_hour_vals\")\n",
    "keywords_for_eval_path = ph.get(\"keywords_for_eval_path\")\n",
    "output_dir = ph.get(\"distance_root_folder\")\n",
    "co_occur_table_file_path = \"%s/occ_table.csv\" % experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "co_occur_df = pd.read_csv(co_occur_table_file_path, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occuring words are in these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_cols = range(1,200,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(co_occur_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "co_occur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculating Jaccard and cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing, functools\n",
    "\n",
    "def get_word_co_occurance_matrix(df, snapshot_id):\n",
    "    dict_for_snapshot = dict()\n",
    "    snapshot_df = co_occur_df[co_occur_df[\"start_time\"]==snapshot_id]\n",
    "    for index, row in snapshot_df.iterrows():\n",
    "        #row = co_occur_df.ix[2]\n",
    "        key, time = row[\"key_word\"], row[\"start_time\"]\n",
    "        is_null_row = pd.isnull(row)\n",
    "        co_occ_dict = dict()\n",
    "        for idx in word_cols:\n",
    "            word, count = row[str(idx)], row[str(idx+1)]\n",
    "            if is_null_row[str(idx)]:\n",
    "                break\n",
    "            elif word == key:\n",
    "                continue\n",
    "            else:\n",
    "                co_occ_dict[word] = count\n",
    "        #print(co_occ_dict, len(co_occ_dict))\n",
    "        if len(co_occ_dict) > 0:\n",
    "            dict_for_snapshot[key] = co_occ_dict\n",
    "    #print(len(dict_for_snapshot), len(snapshot_df))\n",
    "    repr_df = pd.DataFrame(dict_for_snapshot).T\n",
    "    repr_df = repr_df.fillna(0.0)\n",
    "    return repr_df\n",
    "\n",
    "def get_distance(repr_df, dist_type, w1, w2, verbose=False):\n",
    "    dist = None\n",
    "    try:\n",
    "        a = repr_df.ix[w1]\n",
    "        b = repr_df.ix[w2]\n",
    "        if dist_type == \"jaccard\":\n",
    "            bool_a = a > 0.0\n",
    "            bool_b = b > 0.0\n",
    "            dist = ssd.jaccard(bool_a, bool_b)\n",
    "        elif dist_type == \"cosine\":\n",
    "            dist = ssd.cosine(a,b)\n",
    "        else:\n",
    "            raise RuntimeError(\"Invalid distance type!\")\n",
    "    except KeyError as ke:\n",
    "        if verbose:\n",
    "            print(\"KeyError: %s\" % ke)\n",
    "    except:\n",
    "        raise\n",
    "    finally:\n",
    "        return w1, w2, dist\n",
    "\n",
    "def get_distance_toplist(repr_df, dist_type, w1, top_k=100, n_threads=1):\n",
    "    word_list = list(repr_df.index)\n",
    "    if len(word_list) > 0:\n",
    "        try:\n",
    "            # @OstapenkoFC is not present\n",
    "            if w1 in word_list:\n",
    "                word_list.remove(w1)\n",
    "            res = []\n",
    "            for w2 in word_list:\n",
    "                res.append(get_distance(repr_df, dist_type, w1, w2))\n",
    "        except ValueError:\n",
    "            print(w1, word_list)\n",
    "            raise\n",
    "        except:\n",
    "            raise\n",
    "        return pd.DataFrame(res, columns=[\"word_1\",\"word_2\",\"distance\"]).sort_values(\"distance\").head(top_k)\n",
    "    else:\n",
    "        return pd.DataFrame([], columns=[\"word_1\",\"word_2\",\"distance\"])\n",
    "    \n",
    "def get_toplist_for_key_words(co_occur_df, dist_type, query, top_k=100, n_threads=1):\n",
    "    snapshot_id, key_words = query\n",
    "    snapshot_df = get_word_co_occurance_matrix(co_occur_df, snapshot_id)\n",
    "    toplists = []\n",
    "    for kw in key_words:\n",
    "        toplists.append(get_distance_toplist(snapshot_df, dist_type, kw, top_k=top_k, n_threads=n_threads))\n",
    "    res = pd.concat(toplists)\n",
    "    res[\"snapshot_id\"] = snapshot_id\n",
    "    return res\n",
    "\n",
    "def get_toplist_for_multiple_query(co_occur_df, dist_type, queries, max_threads):\n",
    "    if max_threads == 1:\n",
    "        res = []\n",
    "        for q in queries:\n",
    "            res.append(get_toplist_for_key_words(co_occur_df, dist_type, q))\n",
    "    else:\n",
    "        f_partial = functools.partial(get_toplist_for_key_words, co_occur_df, dist_type)\n",
    "        pool = multiprocessing.Pool(processes=max_threads)\n",
    "        res = pool.map(f_partial, queries)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    return pd.concat(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a.) Load keywords for the examined days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting keywords for player co-occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords_df_1 = pd.read_csv(keywords_for_eval_path, sep=\"|\", names=[\"date\",\"key_words\"])\n",
    "keywords_df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting keywords for \"play\" and \"match\" words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "days = [\"2017-05-%.2i\" % i for i in range(28,32)] + [\"2017-06-%.2i\" % i for i in range(1,12)]\n",
    "keywords_df_2 = pd.DataFrame(list(zip(days, [\"{'play', 'match'}\" for i in range(len(days))])), columns=[\"date\",\"key_words\"])\n",
    "keywords_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords_df = pd.concat([keywords_df_1, keywords_df_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.) Filter big table for these days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "co_occur_df[\"date\"] = co_occur_df[\"start_time\"].apply(lambda x: x.split(\"T\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "co_occur_df = co_occur_df[co_occur_df[\"date\"].isin(list(keywords_df[\"date\"].unique()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c.) Query distances (Jaccard, Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queries = []\n",
    "for idx, row in keywords_df.iterrows():\n",
    "    queries += [(\"%sT%.2i:00\" % (row[\"date\"],h),list(eval(row[\"key_words\"]))) for h in time_hour_vals]\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many keywords were missing: but of course at midnight players tend to be mentioned less often: '@OstapenkoFC' missing almost all the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speedup?\n",
    "\n",
    "   * 3min 2s ha 1 sz\u00e1l\n",
    "   * 5 sz\u00e1l: m\u00e1solja a nagy adatot is ez \u00edgy nem lesz j\u00f3!!! sok mem\u00f3ri\u00e1t eszik:\n",
    "      * b\u00e1r sokkal hamarabb k\u00e9sz lett: 1min 24s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "jaccard_res = get_toplist_for_multiple_query(co_occur_df, \"jaccard\", queries, max_threads=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cosine_res = get_toplist_for_multiple_query(co_occur_df, \"cosine\", queries, max_threads=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Export distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_result(f_name, df):\n",
    "    out_df = df[~df[\"distance\"].isnull()]\n",
    "    print(len(out_df))\n",
    "    out_df.to_csv(f_name, sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_result(\"%s/jaccard.dist\" % output_dir, jaccard_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_result(\"%s/cosine.dist\" % output_dir, cosine_res)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dm-3-env]",
   "language": "python",
   "name": "conda-env-dm-3-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}